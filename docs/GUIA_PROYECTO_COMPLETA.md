# GU√çA COMPLETA DEL PROYECTO - Enunciado, Pasos y Configuraci√≥n
---

## ENUNCIADO DEL PROYECTO

### Informaci√≥n General del Proyecto

**Nombre**: Proyecto GitHub + Hugging Face Hub  
**Modalidad**: Pr√°ctico (Hands-on)  
**Entrega**: C√≥digo en GitHub + Modelo en Hugging Face Hub  

---

### Contexto 

Este proyecto est√° dise√±ado para estudiantes que 

**¬øCu√°l es el prop√≥sito?**
- Aprender a usar **herramientas profesionales reales** (GitHub, Hugging Face Hub)
- Entender c√≥mo se trabaja en la industria AI
- Ganar confianza al publicar un modelo entrenado
- Comprender el ciclo completo: C√≥digo ‚Üí Entrenamiento ‚Üí Publicaci√≥n

**¬øQu√© S√ç aprender√°s?**
- ‚úÖ GitHub: crear repo, clonar, commits, push
- ‚úÖ Hugging Face Hub: publicar modelos, compartir
- ‚úÖ Workflow profesional: versionado + publicaci√≥n
- ‚úÖ Reutilizaci√≥n: usar modelos de otros
- ‚úÖ Confianza en AI

---

###  Objetivo General

> **Crear un pipeline completo de ML que demuestre el ciclo profesional:**  
> **C√≥digo (GitHub) ‚Üí Entrenamiento ‚Üí Publicaci√≥n (Hub) ‚Üí Reutilizaci√≥n**

### üîç Objetivos Espec√≠ficos

Al completar este proyecto, ser√°s capaz de:

1. **Gesti√≥n de Versiones (GitHub)**
   - Crear un repositorio en GitHub
   - Clonar c√≥digo de un repositorio remoto
   - Hacer commits con mensajes claros
   - Hacer push a GitHub
   - Documentar tu proyecto en README.md

2. **Publicaci√≥n de Modelos (Hugging Face Hub)**
   - Crear un token de autenticaci√≥n
   - Crear un repositorio de modelo en el Hub
   - Publicar modelos entrenados desde Python
   - Descargar y reutilizar modelos de otros

3. **Pipeline**
   - Cargar modelos preentrenados
   - Hacer predicciones (inferencia)
   - Entrenar un modelo con datos
   - Publicar modelo en la nube

4. **Pensamiento Profesional**
   - Entender por qu√© se versionan c√≥digos
   - Comprender importancia de documentaci√≥n
   - Valorar reproducibilidad
   - Trabajar de forma profesional

---

## üéØ RECOMENDACIONES ESPEC√çFICAS PARA ESTE PROYECTO

### üìä Dataset Recomendado: **IMDb Sentiment Analysis**

```python
from datasets import load_dataset
dataset = load_dataset("imdb")
```

**Por qu√© IMDb:**
- ‚úÖ **Lightweight**: 25K ejemplos (descargas r√°pidas)
- ‚úÖ **Tarea clara**: Clasificaci√≥n binaria (Positivo/Negativo)
- ‚úÖ **M√©tricas obvias**: Accuracy, F1-Score f√°ciles de interpretar
- ‚úÖ **Tiempo**: Fine-tuning ~8 min en GPU RTX 4080 (1 √©poca)
- ‚úÖ **Realista**: Verdadero problema de NLP

**Alternativas:**
- **AG News**: 120K ejemplos, 4 categor√≠as (m√°s ligero)
- **Custom Dataset**: Si tienes datos propios

---

### ü§ñ Modelos Recomendados

#### **Flujo A - Predicci√≥n Baseline: DistilBERT** (RECOMENDADO)

```yaml
modelo: "distilbert-base-uncased-finetuned-sst-2-english"
tarea: "sentiment-analysis"
```

**Caracter√≠sticas:**
| M√©trica | Valor |
|---------|-------|
| Par√°metros | 67M (peque√±o) |
| Tiempo predicci√≥n | ~3 segundos |
| Accuracy esperado | ~93% |
| Ventaja | R√°pido y ligero |

**Alternativas:**
- `bert-base-uncased-finetuned-sst-2-english`: M√°s preciso (+2%) pero m√°s lento
- `roberta-large-mnli`: Vers√°til pero muy pesado (355M par√°metros)

---

#### **Flujo B - Fine-tuning: DistilBERT Base** (RECOMENDADO)

```yaml
modelo_base: "distilbert-base-uncased"
dataset: "imdb"
epochs: 1
batch_size: 16
learning_rate: 2e-5
```

**Caracter√≠sticas:**
| M√©trica | Valor |
|---------|-------|
| Par√°metros | 67M |
| Tiempo entrenamiento | ~8 min (GPU) |
| Accuracy esperado | 95-96% |
| Mejora vs Baseline | +2-3% |

**Configuraci√≥n YAML Completa:**
```yaml
# B_train.yaml
model_name: "distilbert-base-uncased"
dataset_name: "imdb"
output_dir: "./outputs/distilbert-imdb"

training_args:
  num_train_epochs: 1
  per_device_train_batch_size: 16
  per_device_eval_batch_size: 32
  learning_rate: 2e-5
  weight_decay: 0.01
  warmup_steps: 100
  
push_to_hub: true
hub_model_id: "tu_usuario/6_8Proyecto_GitHub+HFHub"
```

---

#### **Flujo A Parte 2 - Tu Modelo Entrenado**

```yaml
# A_finetuned.yaml
modelo: "tu_usuario/6_8Proyecto_GitHub+HFHub"
cache_dir: "./outputs"
```

Descargar√°s autom√°ticamente tu modelo desde Hub y har√°s predicciones.

---

### ‚è±Ô∏è Tiempos Estimados (GPU RTX 4080)

| Paso | Tiempo | Nota |
|------|--------|------|
| Setup entorno | 5 min | Una sola vez |
| Flujo A (baseline) | 1 min | Predicci√≥n r√°pida |
| Flujo B (entrenamiento) | 8 min | 1 √©poca IMDb |
| Flujo A Parte 2 | 1 min | Predicci√≥n con tu modelo |
| **Total** | **~15 min** | De inicio a modelo publicado |

---

### üìã Checklist de Validaci√≥n

Antes de empezar, verifica:

- [ ] GPU disponible: `nvidia-smi` (debe mostrar RTX 4080)
- [ ] PyTorch con CUDA: `python -c "import torch; print(torch.cuda.is_available())"`
- [ ] Token HF v√°lido: `huggingface-cli login` (escribe `hf_xxxxx`)
- [ ] Dataset IMDb descargable: `python -c "from datasets import load_dataset; load_dataset('imdb')`

---

### üìä Componentes del Proyecto

El proyecto se divide en **3 Flujos** que representan el ciclo completo:

#### **Flujo A: Predicci√≥n con Modelo Preentrenado** (Inferencia Inicial)

**Objetivo**: Entender c√≥mo funcionan los modelos sin necesidad de entrenar

**Qu√© har√°s**:
- Descargar modelo preentrenado del Hub (`distilbert-base-uncased-finetuned-sst-2-english`)
- Hacer predicciones en an√°lisis de sentimiento
- Entender flujo: Texto ‚Üí Modelo ‚Üí Predicci√≥n

**Resultado**: 
```
Input:  "I love this project!"
Output: POSITIVE (confianza: 0.999)
```

**Por qu√© es importante**: 
- Entiende que los modelos ya existen y est√°n listos para usar
- No necesitas entrenar para hacer predicciones
- Muchos proyectos reutilizan modelos existentes

---

#### **Flujo B: Entrenamiento y Publicaci√≥n** (El N√∫cleo)

**Objetivo**: Entrenar tu propio modelo y publicarlo profesionalmente

**Qu√© har√°s**:

1. **Descarga de Datos**
   - Descargar dataset SST2 (~8000 rese√±as de pel√≠culas)
   - Cada rese√±a tiene etiqueta: positiva o negativa

2. **Entrenamiento**
   - Cargar modelo base: `distilbert-base-uncased`
   - Entrenar con tus datos durante 1 √©poca
   - Guardar modelo entrenado en `outputs/`

3. **Publicaci√≥n**
   - Subir modelo a tu repositorio Hugging Face Hub
   - Publicar archivos: `model.bin`, `config.json`, `tokenizer.json`, `README.md`

**Resultado**: 
- Modelo en: `https://huggingface.co/tu_usuario/6_7Proyecto_GitHub+HFHub`
- C√≥digo en: `https://github.com/tu_usuario/6_7Proyecto_GitHub+HFHub`

**Por qu√© es importante**:
- Experimentas el ciclo completo profesional
- Aprendes a guardar y compartir modelos
- Otros pueden descargar y usar tu modelo

---

#### **Flujo A Parte 2: Predicci√≥n con Tu Modelo** (Reutilizaci√≥n)

**Objetivo**: Verificar que tu modelo funciona y entender reutilizaci√≥n

**Qu√© har√°s**:
- Descargar TU modelo que publicaste en Hub
- Hacer predicciones con tu modelo entrenado
- Comparar resultados con modelo preentrenado

**Resultado**: 
```
Input:  "This movie is amazing!"
Output: TU_MODELO predice POSITIVE
```

**Por qu√© es importante**:
- Verifica que publicaci√≥n funcion√≥
- Entiende que modelos se pueden compartir y reutilizar
- Simula usar modelo de alguien m√°s

---

###  Entregables Finales

Al terminar el proyecto, tendr√°s:

#### 1. **Repositorio en GitHub** ‚úÖ
```
https://github.com/tu_usuario/6_7Proyecto_GitHub+HFHub

Contiene:
‚îú‚îÄ‚îÄ src/ ...................... Scripts Python
‚îú‚îÄ‚îÄ configs/ ................... Configuraci√≥n YAML
‚îú‚îÄ‚îÄ notebooks/ ................. Notebooks Jupyter
‚îú‚îÄ‚îÄ requirements.txt ........... Dependencias
‚îú‚îÄ‚îÄ setup_gpu_env.sh ........... Script setup
‚îú‚îÄ‚îÄ .gitignore ................. Archivos ignorados
‚îî‚îÄ‚îÄ README.md .................. Tu documentaci√≥n
```

#### 2. **Modelo Publicado en Hub** ‚úÖ
```
https://huggingface.co/tu_usuario/6_7Proyecto_GitHub+HFHub

Contiene:
‚îú‚îÄ‚îÄ model.bin .................. Pesos del modelo
‚îú‚îÄ‚îÄ config.json ................ Configuraci√≥n
‚îú‚îÄ‚îÄ tokenizer.json ............. Tokenizador
‚îî‚îÄ‚îÄ README.md .................. Documentaci√≥n
```

#### 3. **Comprensi√≥n Demostrada** ‚úÖ
- Commits claros en GitHub
- Modelo funcionando en Hub
- README.md documentando el proyecto
- Ejecuci√≥n exitosa de 10 pasos

---

### ‚ú® Criterios de √âxito

Habr√°s completado el proyecto exitosamente cuando:

- ‚úÖ Repositorio GitHub existe y tiene c√≥digo
- ‚úÖ Commits con mensajes claros
- ‚úÖ Modelo publicado en Hugging Face Hub
- ‚úÖ `predict_baseline.py` funciona
- ‚úÖ `train_and_push.py` se ejecut√≥
- ‚úÖ `predict_finetuned.py` carga tu modelo
- ‚úÖ README.md en ra√≠z documentado
- ‚úÖ Entiendes el flujo completo
- ‚úÖ Puedes explicar qu√© aprendiste

##  PASOS DEL PROYECTO (10 pasos totales)

### PASO 0: Preparaci√≥n - Crear Repositorios

**Qu√© hacer**:
1. Crear repositorio en GitHub
2. Crear repositorio en Hugging Face Hub
3. Generar token de HF

**Comando/URLs**:
- GitHub: https://github.com/new
- Hugging Face: https://huggingface.co/new
- Token HF: https://huggingface.co/settings/tokens

**Resultado esperado**:
```
‚úÖ Repositorio GitHub: https://github.com/tu_usuario/6_7Proyecto_GitHub+HFHub
‚úÖ Repositorio HF: https://huggingface.co/tu_usuario/6_7Proyecto_GitHub+HFHub
‚úÖ Token: hf_xxxxxxxxxxxxxxxxxxxxxxxxxxxx
```

---

### PASO 1: Setup - Configurar Entorno 

**Qu√© hacer**:
1. Navegar a carpeta del proyecto
2. Ejecutar script autom√°tico
3. Verificar instalaci√≥n

**Comandos**:
```bash
# Navegar
cd 6_7Proyecto_GitHub+HFHub

# Setup autom√°tico (RECOMENDADO)
bash setup_gpu_env.sh

# O manual:
python -m venv gpu_env
source gpu_env/bin/activate  # Windows: gpu_env\Scripts\activate
pip install -r requirements.txt
```

**Configurar archivo .env**:
```bash
# Copiar template
cp .env.example .env

# Editar .env con tu token
nano .env
# Cambiar: HF_TOKEN=tu_token_aqui
```

**Resultado esperado**:
```
(gpu_env) tu_usuario@computer:~$ ‚úÖ Entorno activo
‚úÖ Dependencias instaladas
‚úÖ .env configurado
```

---

### PASO 2: Estructura - Entender Proyecto 

**Qu√© hacer**:
Explorar carpetas y archivos

**Estructura**:
```
6_7Proyecto_GitHub+HFHub/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ A_inferencia/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ predict_baseline.py .......... Predicci√≥n con modelo preentrenado
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ predict_finetuned.py ........ Predicci√≥n con tu modelo
‚îÇ   ‚îú‚îÄ‚îÄ B_finetuning/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ train_and_push.py ........... Entrenar y publicar
‚îÇ   ‚îî‚îÄ‚îÄ common/
‚îÇ       ‚îú‚îÄ‚îÄ config.py ................... Cargar configuraci√≥n
‚îÇ       ‚îî‚îÄ‚îÄ hf_auth.py .................. Autenticaci√≥n HF

‚îú‚îÄ‚îÄ configs/
‚îÇ   ‚îú‚îÄ‚îÄ A_baseline.yaml ................. Config Flujo A (preentrenado)
‚îÇ   ‚îú‚îÄ‚îÄ B_train.yaml .................... Config Flujo B (entrenar)
‚îÇ   ‚îî‚îÄ‚îÄ A_finetuned.yaml ............... Config Flujo A (tu modelo)

‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ Flujo_A_Inferencia.ipynb ........ Template predicci√≥n
‚îÇ   ‚îî‚îÄ‚îÄ Flujo_B_FineTuning.ipynb ........ Template entrenamiento

‚îú‚îÄ‚îÄ data/ ............................ Datasets (creado auto)
‚îú‚îÄ‚îÄ outputs/ ......................... Modelos entrenados (creado auto)
‚îú‚îÄ‚îÄ requirements.txt ................. Dependencias Python
‚îú‚îÄ‚îÄ setup_gpu_env.sh ................. Script autom√°tico
‚îî‚îÄ‚îÄ .env ............................ Variables de entorno (NO compartir)
```

**Archivos Clave**:
| Archivo | Qu√© hace |
|---------|----------|
| `predict_baseline.py` | Carga modelo preentrenado y predice |
| `train_and_push.py` | Entrena modelo y lo publica |
| `predict_finetuned.py` | Carga tu modelo y predice |
| `*.yaml` | Configuraci√≥n de par√°metros |
| `.env` | Token y URLs (secreto) |

---

### PASO 3: Flujo A - Editar Configuraci√≥n 

**Qu√© hacer**:
Editar archivo de configuraci√≥n para predicci√≥n baseline

**Archivo**: `configs/A_baseline.yaml`

**Contenido original**:
```yaml
model_name: "distilbert-base-uncased-finetuned-sst-2-english"
task: "sentiment-analysis"
test_input: "I love this project!"
```

**Qu√© significa**:
- `model_name`: Modelo a descargar del Hub
- `task`: Tipo de tarea (an√°lisis de sentimiento)
- `test_input`: Texto para predicci√≥n

**Puedes cambiar**:
- `test_input`: "Your text here"

**Resultado esperado**:
‚úÖ Archivo guardado con cambios

---

### PASO 4: Flujo A - Ejecutar Predicci√≥n Baseline 

**Qu√© hacer**:
Ejecutar predicci√≥n con modelo preentrenado

**Comando**:
```bash
# Asegurar que entorno est√° activado
source gpu_env/bin/activate

# Ejecutar predicci√≥n
python src/A_inferencia/predict_baseline.py
```

**Qu√© pasa**:
1. Descarga modelo del Hub
2. Carga configuraci√≥n
3. Hace predicci√≥n
4. Muestra resultado

**Resultado esperado**:
```
Texto: "I love this project!"
Predicci√≥n: POSITIVE (confianza: 0.999)
‚úÖ Funciona!
```

**Si falla**:
- ‚ùå "ModuleNotFoundError": `bash setup_gpu_env.sh`
- ‚ùå "HF_TOKEN not found": Editar `.env`
- ‚ùå Conexi√≥n: Verificar internet

---

### PASO 5: Flujo B - Editar Configuraci√≥n Entrenamiento 

**Qu√© hacer**:
Editar configuraci√≥n para entrenar modelo

**Archivo**: `configs/B_train.yaml`

**Par√°metros principales**:
```yaml
model_name: "distilbert-base-uncased"        # Modelo base
dataset_name: "sst2"                          # Dataset: 8000 ejemplos
num_epochs: 1                                 # 1 √©poca = 10-15 min
batch_size: 8                                 # Procesa 8 textos a la vez
learning_rate: 2e-5                          # Velocidad aprendizaje
output_dir: "outputs"                        # D√≥nde guardar modelo
hf_repo_id: "tu_usuario/6_7Proyecto_GitHub+HFHub"  # CAMBIAR ESTO
```

**Configuraci√≥n recomendada**:
- Para GPU: `num_epochs: 1`, `batch_size: 8`
- Para CPU: `num_epochs: 1`, `batch_size: 4`

**Archivo .env debe tener**:
```
HF_TOKEN=hf_tutoken_aqui
GITHUB_REPO=https://github.com/tu_usuario/6_7Proyecto_GitHub+HFHub
HF_REPO=https://huggingface.co/tu_usuario/6_7Proyecto_GitHub+HFHub
```

**Resultado esperado**:
‚úÖ Configuraci√≥n actualizada

---

### PASO 6: Flujo B - Entrenar Modelo 

**Qu√© hacer**:
Ejecutar entrenamiento. Este apartado no va a ser valorado, es preferible un peor resultado del modelo pero conseguir finalizar todos los pasos. 

**Comando**:
```bash
python src/B_finetuning/train_and_push.py
```

**Qu√© pasa** (en orden):
1. Verifica credenciales
2. Descarga dataset SST2 (~8000 ejemplos)
3. Carga modelo distilbert-base-uncased
4. **Entrena por 1 √©poca** ‚Üê El paso m√°s largo
5. Guarda modelo en `outputs/`
6. Sube a tu repositorio HF Hub

**Tiempo estimado**:
- GPU: 10-15 minutos
- CPU: 1-2 horas

**Output esperado**:
```
Loading dataset...
Training epoch 1/1... [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100%
Saving model to outputs/
Pushing to Hub...
‚úÖ Model pushed to hub!
```

**Si falla**:
- ‚ùå "CUDA out of memory": Bajar `batch_size` en YAML
- ‚ùå "Connection error": Verificar token en `.env`
- ‚ùå "Authentication failed": Token inv√°lido

---

### PASO 7: Verificar Modelo en Hub 

**Qu√© hacer**:
Confirmar que modelo est√° publicado

**URL**: 
```
https://huggingface.co/tu_usuario/6_7Proyecto_GitHub+HFHub
```

**Verificar que existe**:
- ‚úÖ Repositorio visible
- ‚úÖ Archivos: `model.bin`, `config.json`, `tokenizer.json`
- ‚úÖ README.md

**Resultado esperado**:
```
‚úÖ Tu modelo est√° publicado en Hub
‚úÖ Cualquiera puede descargar y usar
```

---

### PASO 8: Flujo A Parte 2 - Usar Tu Modelo 

**Qu√© hacer**:
Configurar y ejecutar con tu modelo

**Archivo**: `configs/A_finetuned.yaml`

**Cambiar de**:
```yaml
model_name: "distilbert-base-uncased-finetuned-sst-2-english"
```

**A**:
```yaml
model_name: "tu_usuario/6_7Proyecto_GitHub+HFHub"
```

**Comando**:
```bash
python src/A_inferencia/predict_finetuned.py
```

**Qu√© pasa**:
1. Descarga TU modelo del Hub
2. Hace predicci√≥n con tu modelo
3. Muestra resultado

**Resultado esperado**:
```
Descargando modelo de: tu_usuario/6_7Proyecto_GitHub+HFHub
Texto: "This movie is amazing!"
Predicci√≥n: POSITIVE
‚úÖ Tu modelo funciona!
```

---

### PASO 9: Versionado en GitHub 

**Qu√© hacer**:
Publicar c√≥digo en GitHub

**Comandos**:
```bash
# Clonar repositorio
git clone https://github.com/tu_usuario/6_7Proyecto_GitHub+HFHub.git
cd 6_7Proyecto_GitHub+HFHub

# Configurar git
git config user.name "Tu Nombre"
git config user.email "tu@email.com"

# Copiar archivos
cp -r src/ configs/ notebooks/ .gitignore .env.example requirements.txt setup_gpu_env.sh .

# Hacer commits
git add .
git commit -m "Proyecto inicial: GitHub + Hugging Face Hub"
git branch -M main
git push -u origin main
```

**Verificar en GitHub**:
```
https://github.com/tu_usuario/6_7Proyecto_GitHub+HFHub
‚úÖ Todos los archivos est√°n all√≠
‚úÖ .env NO est√° (seguridad)
```

---

### PASO 10: Validaci√≥n Final 

**Qu√© hacer**:
Verificar que todo funciona

**Checklist**:
- [ ] `python src/A_inferencia/predict_baseline.py` funciona
- [ ] Hub tiene modelo publicado
- [ ] GitHub tiene c√≥digo
- [ ] `python src/A_inferencia/predict_finetuned.py` funciona
- [ ] Entiendes GitHub ‚Üí Hub flujo

**Resultado esperado**:
```
‚úÖ Todo funciona
‚úÖ Modelo publicado
‚úÖ C√≥digo versionado
‚úÖ ¬°Proyecto completo!
```

---

##  CONFIGURACI√ìN COMPLETA

### 1. Variables de Entorno (.env)

**Archivo**: `.env` (NUNCA compartir)

```ini
# Token de Hugging Face (de https://huggingface.co/settings/tokens)
HF_TOKEN=hf_tutoken_aqui

# URLs de tus repositorios
GITHUB_REPO=https://github.com/tu_usuario/6_7Proyecto_GitHub+HFHub
HF_REPO=https://huggingface.co/tu_usuario/6_7Proyecto_GitHub+HFHub
```

**C√≥mo obtener**:
- Token HF: https://huggingface.co/settings/tokens ‚Üí "New token" ‚Üí Copy
- GitHub URL: https://github.com/new ‚Üí Copiar
- HF URL: https://huggingface.co/new ‚Üí Copiar

---

### 2. Configuraci√≥n YAML

#### A_baseline.yaml (Flujo A - Predicci√≥n Preentrenada)
```yaml
model_name: "distilbert-base-uncased-finetuned-sst-2-english"
task: "sentiment-analysis"
test_input: "I love this project!"
```

**Par√°metros**:
- `model_name`: Modelo del Hub a usar
- `task`: Tipo de tarea
- `test_input`: Texto para predicci√≥n

**Modelos alternativos**:
- `"bert-base-uncased-finetuned-wnli"`
- `"distilbert-base-uncased"`

---

#### B_train.yaml (Flujo B - Entrenamiento)
```yaml
# Modelo
model_name: "distilbert-base-uncased"

# Dataset
dataset_name: "sst2"
num_train_samples: null  # null = todas

# Entrenamiento
num_epochs: 1
batch_size: 8
learning_rate: 2e-5
max_length: 128

# Guardado
output_dir: "outputs"
hf_repo_id: "tu_usuario/6_7Proyecto_GitHub+HFHub"

# Hardware
use_cuda: true  # false para CPU
```

**Qu√© significa cada par√°metro**:
- `num_epochs`: Cu√°ntas veces procesa el dataset (1 = 10-15 min)
- `batch_size`: Textos procesados a la vez (‚Üì menos memoria)
- `learning_rate`: Qu√© tan r√°pido aprende (2e-5 es est√°ndar)
- `max_length`: M√°ximo de palabras por texto (128 = ~512 caracteres)

**Configuraci√≥n para diferentes hardwares**:

GPU potente:
```yaml
batch_size: 16
num_epochs: 3
```

GPU modesta:
```yaml
batch_size: 8
num_epochs: 1
```

CPU:
```yaml
batch_size: 4
num_epochs: 1
use_cuda: false
```

---

#### A_finetuned.yaml (Flujo A - Tu Modelo)
```yaml
model_name: "tu_usuario/6_7Proyecto_GitHub+HFHub"
task: "sentiment-analysis"
test_input: "This is amazing!"
```

**Lo √∫nico que cambi√≥**:
- `model_name`: Ahora es tu usuario/repositorio

---

### 3. Dependencies (requirements.txt)

```
transformers==4.36.2
torch==2.1.2
datasets==2.16.1
scikit-learn==1.3.2
PyYAML==6.0.1
huggingface_hub==0.20.2
python-dotenv==1.0.0
```

**Qu√© es cada uno**:
- `transformers`: Modelos PLN
- `torch`: Framework deep learning
- `datasets`: Descargar datasets p√∫blicos
- `scikit-learn`: M√©tricas y evaluaci√≥n
- `PyYAML`: Leer archivos YAML
- `huggingface_hub`: Publicar en Hub
- `python-dotenv`: Cargar variables de entorno

---

### 4. Archivos Ignorados (.gitignore)

```
# Secretos (NUNCA compartir)
.env
*.env

# Datos (muy grandes)
data/
outputs/

# Entorno virtual
gpu_env/
venv/

# Python
__pycache__/
*.pyc
*.pyo

# IDE
.vscode/
.idea/
*.swp

# OS
.DS_Store
```

---

## üìã CHECKLIST DE CONFIGURACI√ìN

Antes de ejecutar, verifica:

- [ ] **Cuentas**:
  - [ ] GitHub account creada
  - [ ] HF account creada
  - [ ] Token HF generado

- [ ] **Repositorios**:
  - [ ] GitHub repo creado (vac√≠o)
  - [ ] HF Hub repo creado (vac√≠o)
  - [ ] Mismo nombre en ambos

- [ ] **Software**:
  - [ ] Python 3.8+ instalado
  - [ ] Git instalado
  - [ ] Conexi√≥n a internet

- [ ] **Archivo .env**:
  - [ ] `.env` existe
  - [ ] `HF_TOKEN=hf_...` completado
  - [ ] Rutas correctas

- [ ] **YAML configs**:
  - [ ] `A_baseline.yaml` revisado
  - [ ] `B_train.yaml` - hf_repo_id actualizado
  - [ ] `A_finetuned.yaml` - model_name actualizado

- [ ] **Hardware**:
  - [ ] GPU disponible (opcional, CPU tambi√©n funciona)
  - [ ] 20GB disco libre (m√≠nimo)
  - [ ] 8GB RAM (16GB recomendado)

---

## üîß TROUBLESHOOTING CONFIGURACI√ìN

| Error | Causa | Soluci√≥n |
|-------|-------|----------|
| `ModuleNotFoundError: transformers` | Dependencies no instaladas | `bash setup_gpu_env.sh` |
| `HF_TOKEN not found` | .env no configurado | Editar `.env` + agregar token |
| `CUDA out of memory` | batch_size muy grande | Bajar batch_size en YAML |
| `Permission denied setup_gpu_env.sh` | Script no ejecutable | `chmod +x setup_gpu_env.sh` |
| `Connection refused Hub` | Token inv√°lido | Verificar token en `.env` |
| `FileNotFoundError: configs/B_train.yaml` | Ruta incorrecta | Ejecutar desde carpeta ra√≠z |

---
