# ğŸ““ Notebooks - Estructura de Tareas BÃ¡sicas

Dos cuadernos para el flujo completo Aâ†’Bâ†’A del proyecto.

## ğŸ”„ Flujo de EjecuciÃ³n

```
1. Flujo_A_Inferencia.ipynb (Paso 2: Modelo Base)
   â†“
2. Flujo_B_FineTuning.ipynb (Entrenamiento Completo)
   â†“
3. Flujo_A_Inferencia.ipynb (Paso 3: Modelo Custom)
```

---

## ğŸ“˜ Flujo_A_Inferencia.ipynb

**PropÃ³sito**: Probar predicciones con modelo base y modelo fine-tuneado.

### Tareas BÃ¡sicas

**Paso 1: Setup**
- Importar librerÃ­as
- Cargar variables de entorno (.env)
- Configurar rutas del proyecto

**Paso 2: Modelo Base (FLUJO A1)**
- Cargar configuraciÃ³n A_baseline.yaml
- Crear pipeline para sentiment-analysis
- Realizar predicciÃ³n con texto de prueba
- Mostrar resultado

**Paso 3: Modelo Custom (FLUJO A2)**
- Cargar configuraciÃ³n A_finetuned.yaml
- Crear pipeline para sentiment-analysis
- Realizar predicciÃ³n con MISMO texto
- Mostrar resultado

**Paso 4: ComparaciÃ³n**
- Tabla comparativa (base vs fine-tuned)
- AnÃ¡lisis de diferencias
- Tasa de concordancia

**Paso 5: Ãrea Libre**
- Probar textos personalizados
- Experimentar con diferentes ejemplos

---

## ğŸš€ Flujo_B_FineTuning.ipynb

**PropÃ³sito**: Entrenamiento y publicaciÃ³n del modelo en Hub.

### Tareas BÃ¡sicas

**Paso 1: Setup**
- Importar librerÃ­as
- Cargar configuraciÃ³n
- Verificar GPU

**Paso 2: AutenticaciÃ³n**
- Verificar HF_TOKEN
- Login en Hugging Face Hub

**Paso 3: Datos**
- Cargar dataset SST2
- Crear subsets (reducidos para rapidez)
- Mostrar ejemplos

**Paso 4: Modelo**
- Cargar modelo y tokenizador
- Tokenizar dataset
- Preparar formato torch

**Paso 5: Entrenamiento**
- Configurar argumentos
- Crear Trainer
- **Entrenar** (â±ï¸ 30 min GPU / 3h CPU)

**Paso 6: EvaluaciÃ³n**
- Evaluar modelo
- Mostrar mÃ©tricas finales

**Paso 7: PublicaciÃ³n**
- Push a Hugging Face Hub
- Mostrar URL del repositorio

---

## ğŸ“Š Tabla de EjecuciÃ³n Recomendada

| Notebook | DuraciÃ³n | GPU | CPU | Orden |
|----------|----------|-----|-----|-------|
| Flujo_A_Inferencia (Paso 2) | 2 min | âœ“ | âœ“ | 1Âº |
| Flujo_B_FineTuning | 30 min | âœ“ | 3h | 2Âº |
| Flujo_A_Inferencia (Paso 3) | 2 min | âœ“ | âœ“ | 3Âº |

---

## ğŸ¯ Tareas por Celda (MÃ­nimo)

### Flujo A
- [ ] **Celda 1**: Importaciones + Setup
- [ ] **Celda 2**: Load config baseline
- [ ] **Celda 3**: Create pipeline baseline
- [ ] **Celda 4**: Predict baseline
- [ ] **Celda 5**: Load config finetuned
- [ ] **Celda 6**: Create pipeline finetuned
- [ ] **Celda 7**: Predict finetuned
- [ ] **Celda 8**: Compare results

### Flujo B
- [ ] **Celda 1**: Importaciones + Setup
- [ ] **Celda 2**: Load config
- [ ] **Celda 3**: Login HF
- [ ] **Celda 4**: Load dataset
- [ ] **Celda 5**: Create subsets
- [ ] **Celda 6**: Load model + tokenizer
- [ ] **Celda 7**: Tokenize dataset
- [ ] **Celda 8**: Configure training
- [ ] **Celda 9**: Train model (â±ï¸)
- [ ] **Celda 10**: Evaluate
- [ ] **Celda 11**: Push to Hub

---

## ğŸ’¡ Notas Importantes

1. **Flujo A es rÃ¡pido**: 2-3 minutos por paso
2. **Flujo B toma tiempo**: 30 min (GPU) o 3 horas (CPU)
3. **Orden es crÃ­tico**: B debe completarse antes de probar Flujo A paso 3
4. **Token HF**: Necesario para Flujo B
5. **Subsets reducidos**: El notebook usa 5000 train + 1000 eval para rapidez

---

## ğŸ“ Checklist de EjecuciÃ³n

```bash
# Antes de empezar
[ ] HF_TOKEN configurado en .env
[ ] ConexiÃ³n a internet
[ ] GPU disponible (recomendado para Flujo B)

# Flujo A - Paso 2
[ ] Setup completado
[ ] Config baseline cargada
[ ] Pipeline creado
[ ] PredicciÃ³n realizada

# Flujo B
[ ] AutenticaciÃ³n OK
[ ] Dataset descargado
[ ] Modelo entrenado
[ ] Publicado en Hub

# Flujo A - Paso 3
[ ] Config finetuned cargada
[ ] Pipeline creado
[ ] PredicciÃ³n realizada
[ ] ComparaciÃ³n hecha
```

---

## ğŸ”— Enlaces Ãštiles

- [Hugging Face Hub](https://huggingface.co)
- [Transformers Docs](https://huggingface.co/docs/transformers)
- [SST2 Dataset](https://huggingface.co/datasets/glue/viewer/sst2)
- [DistilBERT Model](https://huggingface.co/distilbert-base-uncased)

